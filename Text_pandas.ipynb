{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series and Index are equipped with a set of string processing methods that make it easy to operate on each element of the array. Perhaps most importantly, these methods exclude missing/NA values automatically. These are accessed via the str attribute and generally have names matching the equivalent (scalar) built-in string methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(\n",
    "    [\"A\", \"B\", \"C\", \"Aaba\", \"Baca\", np.nan, \"CABA\", \"dog\", \"cat\"], dtype=\"string\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.Index([\" jack\", \"jill \", \" jesse \", \"frank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The string methods on Index are especially useful for cleaning up or transforming DataFrame columns. For instance, you may have columns with leading or trailing whitespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    np.random.randn(3, 2), columns=[\" Column A \", \" Column B \"], index=range(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since df.columns is an Index object, we can use the .str accessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These string methods can then be used to clean up the columns as needed. Here we are removing leading and trailing whitespaces, lower casing all names, and replacing any remaining whitespaces with underscores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a Series where lots of elements are repeated (i.e. the number of unique elements in the Series is a lot smaller than the length of the Series), it can be faster to convert the original Series to one of type category and then use .str.<method> or .dt.<property> on that. The performance difference comes from the fact that, for Series of type category, the string operations are done on the .categories and not on each element of the Series.\n",
    "\n",
    "# Please note that a Series of type category with string .categories has some limitations in comparison to Series of type string (e.g. you can’t add strings to each other: s + \" \" + s won’t work if s is a Series of type category). Also, .str methods which operate on elements of type list are not available on such a Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting and replacing strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = pd.Series([\"a_b_c\", \"c_d_e\", np.nan, \"f_g_h\"], dtype=\"string\")\n",
    "s2.str.split(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elements in the split lists can be accessed using get or [] notation:\n",
    "s2.str.split(\"_\").str.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.str.split(\"_\").str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is easy to expand this to return a DataFrame using expand.\n",
    "s2.str.split(\"_\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When original Series has StringDtype, the output columns will all be StringDtype as well.\n",
    "# It is also possible to limit the number of splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.str.split(\"_\", expand=True, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rsplit is similar to split except it works in the reverse direction, i.e., from the end of the string to the beginning of the string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.str.rsplit(\"_\", expand=True, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace optionally uses regular expressions:\n",
    "s3 = pd.Series(\n",
    "    [\"A\", \"B\", \"C\", \"Aaba\", \"Baca\", \"\", np.nan, \"CABA\", \"dog\", \"cat\"],\n",
    "    dtype=\"string\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.str.replace(\"^.a|dog\", \"XX-XX \", case=False, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some caution must be taken when dealing with regular expressions! The current behavior is to treat single character patterns as literal strings, even when regex is set to True. This behavior is deprecated and will be removed in a future version so that the regex keyword is always respected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want literal replacement of a string (equivalent to str.replace()), you can set the optional regex parameter to False, rather than escaping each character. In this case both pat and repl must be strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f you want literal replacement of a string (equivalent to str.replace()), you can set the optional regex parameter to False, rather than escaping each character. In this case both pat and repl must be strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollars = pd.Series([\"12\", \"-$10\", \"$10,000\"], dtype=\"string\")\n",
    "dollars.str.replace(r\"-\\$\", \"-\", regex=True)\n",
    "dollars.str.replace(\"-$\", \"-\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The replace method can also take a callable as replacement. It is called on every pat using re.sub(). The callable should expect one positional argument (a regex object) and return a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverse every lowercase alphabetic word\n",
    "pat = r\"[a-z]+\"\n",
    "\n",
    "def repl(m):\n",
    "    return m.group(0)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([\"foo 123\", \"bar baz\", np.nan], dtype=\"string\").str.replace(\n",
    "    pat, repl, regex=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = r\"(?P<one>\\w+) (?P<two>\\w+) (?P<three>\\w+)\"\n",
    "\n",
    "def repl(m):\n",
    "    return m.group(\"two\").swapcase()\n",
    "\n",
    "\n",
    "pd.Series([\"Foo Bar Baz\", np.nan], dtype=\"string\").str.replace(\n",
    "    pat, repl, regex=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The replace method also accepts a compiled regular expression object from re.compile() as a pattern. All flags should be included in the compiled regular expression object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex_pat = re.compile(r\"^.a|dog\", flags=re.IGNORECASE)\n",
    "s3.str.replace(regex_pat, \"XX-XX \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including a flags argument when calling replace with a compiled regular expression object will raise a ValueError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([\"str_foo\", \"str_bar\", \"no_prefix\"])\n",
    "s.str.removeprefix(\"str_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([\"foo_str\", \"bar_str\", \"no_suffix\"])\n",
    "\n",
    "s.str.removesuffix(\"_str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting substrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The extract method accepts a regular expression with at least one capture group.\n",
    "\n",
    "# Extracting a regular expression with more than one group returns a DataFrame with one column per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(\n",
    "    [\"a1\", \"b2\", \"c3\"],\n",
    "    dtype=\"string\",\n",
    ").str.extract(r\"([ab])(\\d)\", expand=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elements that do not match return a row filled with NaN. Thus, a Series of messy strings can be “converted” into a like-indexed Series or DataFrame of cleaned-up or more useful strings, without necessitating get() to access tuples or re.match objects. The dtype of the result is always object, even if no match is found and the result only contains NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\00824732\\Desktop\\geek6\\personal\\Text_pandas.ipynb Cell 41\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/00824732/Desktop/geek6/personal/Text_pandas.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pd\u001b[39m.\u001b[39mSeries([\u001b[39m\"\u001b[39m\u001b[39ma1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mb2\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mc3\u001b[39m\u001b[39m\"\u001b[39m], dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mextract(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/00824732/Desktop/geek6/personal/Text_pandas.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(?P<letter>[ab])(?P<digit>\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md)\u001b[39m\u001b[39m\"\u001b[39m, expand\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/00824732/Desktop/geek6/personal/Text_pandas.ipynb#X54sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.Series([\"a1\", \"b2\", \"c3\"], dtype=\"string\").str.extract(\n",
    "    r\"(?P<letter>[ab])(?P<digit>\\d)\", expand=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(\n",
    "    [\"a1\", \"b2\", \"3\"],\n",
    "    dtype=\"string\",\n",
    ").str.extract(r\"([ab])?(\\d)\", expand=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also be used. Note that any capture group names in the regular expression will be used for column names; otherwise capture group numbers will be used.\n",
    "\n",
    "# Extracting a regular expression with one group returns a DataFrame with one column if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([\"a1\", \"b2\", \"c3\"], dtype=\"string\").str.extract(r\"[ab](\\d)\", expand=True)\n",
    "# It returns a Series if expand=False.\n",
    "pd.Series([\"a1\", \"b2\", \"c3\"], dtype=\"string\").str.extract(r\"[ab](\\d)\", expand=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all matches in each subject (extractall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unlike extract (which returns only the first match),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([\"a1\", \"b2\", \"c3\"], [\"A11\", \"B22\", \"C33\"], dtype=\"string\")\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the extractall method returns every match. The result of extractall is always a DataFrame with a MultiIndex on its rows. The last level of the MultiIndex is named match and indicates the order in the subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.str.extractall(two_groups)\n",
    "s = pd.Series([\"a3\", \"b3\", \"c2\"], dtype=\"string\")\n",
    "# then extractall(pat).xs(0, level='match') gives the same result as extract(pat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index.str.extract(\"(?P<letter>[a-zA-Z])\", expand=True)\n",
    "# It returns an Index if expand=False.\n",
    "s.index.str.extract(\"(?P<letter>[a-zA-Z])\", expand=False)\n",
    "# Calling on an Index with a regex with more than one capture group returns a DataFrame if expand=True.\n",
    "s.index.str.extract(\"(?P<letter>[a-zA-Z])([0-9]+)\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([\"a1a2\", \"b1\", \"c1\"], index=[\"A\", \"B\", \"C\"], dtype=\"string\")\n",
    "two_groups = \"(?P<letter>[a-z])(?P<digit>[0-9])\"\n",
    "s.str.extract(two_groups, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the extractall method returns every match. The result of extractall is always a DataFrame with a MultiIndex on its rows. The last level of the MultiIndex is named match and indicates the order in the subject.\n",
    "s.str.extractall(two_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when each subject string in the Series has exactly one match,\n",
    "s = pd.Series([\"a3\", \"b3\", \"c2\"], dtype=\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_result = s.str.extract(two_groups, expand=True)\n",
    "extractall_result = s.str.extractall(two_groups)\n",
    "extractall_result.xs(0, level=\"match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index also supports .str.extractall. It returns a DataFrame which has the same result as a Series.str.extractall with a default index (starts from 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Index([\"a1a2\", \"b1\", \"c1\"]).str.extractall(two_groups)\n",
    "pd.Series([\"a1a2\", \"b1\", \"c1\"], dtype=\"string\").str.extractall(two_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for strings that match or contain a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   You can check whether elements contain a pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"[0-9][a-z]\"\n",
    "pd.Series(\n",
    "    [\"1\", \"2\", \"3a\", \"3b\", \"03c\", \"4dx\"],\n",
    "    dtype=\"string\",\n",
    ").str.contains(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(\n",
    "    [\"1\", \"2\", \"3a\", \"3b\", \"03c\", \"4dx\"],\n",
    "    dtype=\"string\",\n",
    ").str.match(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(\n",
    "    [\"1\", \"2\", \"3a\", \"3b\", \"03c\", \"4dx\"],\n",
    "    dtype=\"string\",\n",
    ").str.fullmatch(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- The distinction between match, fullmatch, and contains is strictness: fullmatch tests whether the entire string matches the regular expression; match tests whether there is a match of the regular expression that begins at the first character of the string; and contains tests whether there is a match of the regular expression at any position within the string.\n",
    "\n",
    "The corresponding functions in the re package for these three match modes are re.fullmatch, re.match, and re.search, respectively.Methods like match, fullmatch, contains, startswith, and endswith take an extra na argument so missing values can be considered True or False: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s4 = pd.Series(\n",
    "    [\"A\", \"B\", \"C\", \"Aaba\", \"Baca\", np.nan, \"CABA\", \"dog\", \"cat\"], dtype=\"string\"\n",
    ")\n",
    "s4.str.contains(\"A\", na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are several ways to concatenate a Series or Index, either with itself or others, all based on cat(), resp. Index.str.cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating a single Series into a string. The content of a Series (or Index) can be concatenated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([\"a\", \"b\", \"c\", \"d\"], dtype=\"string\")\n",
    "s.str.cat(sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, missing values are ignored. Using na_rep, they can be given a representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.Series([\"a\", \"b\", np.nan, \"d\"], dtype=\"string\")\n",
    "t.str.cat(sep=\",\")\n",
    "t.str.cat(sep=\",\", na_rep=\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating a Series and something list-like into a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first argument to cat() can be a list-like object, provided that it matches the length of the calling Series (or Index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\00824732\\Desktop\\geek6\\personal\\Text_pandas.ipynb Cell 60\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/00824732/Desktop/geek6/personal/Text_pandas.ipynb#Y154sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m s\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcat([\u001b[39m\"\u001b[39m\u001b[39mA\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mD\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "s.str.cat([\"A\", \"B\", \"C\", \"D\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values on either side will result in missing values in the result as well, unless na_rep is specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.str.cat(t)\n",
    "s.str.cat(t, na_rep=\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# he first argument to cat() can be a list-like object, provided that it matches the length of the calling Series (or Index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.str.cat([\"A\", \"B\", \"C\", \"D\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Missing values on either side will result in missing values in the result as well, unless na_rep is specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.str.cat(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.str.cat(t, na_rep=\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating a Series and something array-like into a Series -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameter others can also be two-dimensional. In this case, the number or rows must match the lengths of the calling Series (or Index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat([t, s], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s.str.cat(d, na_rep=\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating a Series and an indexed object into a Series, with alignment -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For concatenation with a Series or DataFrame, it is possible to align the indexes before concatenation by setting the join-keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = pd.Series([\"b\", \"d\", \"a\", \"c\"], index=[1, 3, 0, 2], dtype=\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.str.cat(u)\n",
    "s.str.cat(u, join=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The usual options are available for join (one of 'left', 'outer', 'inner', 'right'). In particular, alignment also means that the different lengths do not need to coincide anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the join keyword is not passed, the method cat() will currently fall back to the behavior before version 0.23.0 (i.e. no alignment), but a FutureWarning will be raised if any of the involved indexes differ, since this default will change to join='left' in a future version.## Concatenating a Series and an indexed object into a Series, with alignment -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.Series([\"z\", \"a\", \"b\", \"d\", \"e\"], index=[-1, 0, 1, 3, 4], dtype=\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.str.cat(v, join=\"left\", na_rep=\"-\")\n",
    "\n",
    "s.str.cat(v, join=\"outer\", na_rep=\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the join keyword is not passed, the method cat() will currently fall back to the behavior before version 0.23.0 (i.e. no alignment), but a FutureWarning will be raised if any of the involved indexes differ, since this default will change to join='left' in a future version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same alignment can be used when others is a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = d.loc[[3, 2, 1, 0], :]\n",
    "s.str.cat(f, join=\"left\", na_rep=\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating a Series and many objects into a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several array-like items (specifically: Series, Index, and 1-dimensional variants of np.ndarray) can be combined in a list-like container (including iterators, dict-views, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.str.cat([u, u.to_numpy()], join=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All elements without an index (e.g. np.ndarray) within the passed list-like must match in length to the calling Series (or Index), but Series and Index may have arbitrary length (as long as alignment is not disabled with join=None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.str.cat([v, u, u.to_numpy()], join=\"outer\", na_rep=\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using join='right' on a list-like of others that contains different indexes, the union of these indexes will be used as the basis for the final concatenation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.str.cat([u.loc[[3]], v.loc[[-1, 0]]], join=\"right\", na_rep=\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([\"a\", \"a|b\", np.nan, \"a|c\"], dtype=\"string\")\n",
    "s.str.get_dummies(sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing with str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use [] notation to directly index by position locations. If you index past the end of the string, the result will be a NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Index also supports get_dummies which returns a MultiIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.Index([\"a\", \"a|b\", np.nan, \"a|c\"])\n",
    "\n",
    "idx.str.get_dummies(sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method summary\n",
    "# Method\n",
    "\n",
    "# Description\n",
    "\n",
    "# cat()\n",
    "\n",
    "# Concatenate strings\n",
    "\n",
    "# split()\n",
    "\n",
    "# Split strings on delimiter\n",
    "\n",
    "# rsplit()\n",
    "\n",
    "# Split strings on delimiter working from the end of the string\n",
    "\n",
    "# get()\n",
    "\n",
    "# Index into each element (retrieve i-th element)\n",
    "\n",
    "# join()\n",
    "\n",
    "# Join strings in each element of the Series with passed separator\n",
    "\n",
    "# get_dummies()\n",
    "\n",
    "# Split strings on the delimiter returning DataFrame of dummy variables\n",
    "\n",
    "# contains()\n",
    "\n",
    "# Return boolean array if each string contains pattern/regex\n",
    "\n",
    "# replace()\n",
    "\n",
    "# Replace occurrences of pattern/regex/string with some other string or the return value of a callable given the occurrence\n",
    "\n",
    "# removeprefix()\n",
    "\n",
    "# Remove prefix from string, i.e. only remove if string starts with prefix.\n",
    "\n",
    "# removesuffix()\n",
    "\n",
    "# Remove suffix from string, i.e. only remove if string ends with suffix.\n",
    "\n",
    "# repeat()\n",
    "\n",
    "# Duplicate values (s.str.repeat(3) equivalent to x * 3)\n",
    "\n",
    "# pad()\n",
    "\n",
    "# Add whitespace to left, right, or both sides of strings\n",
    "\n",
    "# center()\n",
    "\n",
    "# Equivalent to str.center\n",
    "\n",
    "# ljust()\n",
    "\n",
    "# Equivalent to str.ljust\n",
    "\n",
    "# rjust()\n",
    "\n",
    "# Equivalent to str.rjust\n",
    "\n",
    "# zfill()\n",
    "\n",
    "# Equivalent to str.zfill\n",
    "\n",
    "# wrap()\n",
    "\n",
    "# Split long strings into lines with length less than a given width\n",
    "\n",
    "# slice()\n",
    "\n",
    "# Slice each string in the Series\n",
    "\n",
    "# slice_replace()\n",
    "\n",
    "# Replace slice in each string with passed value\n",
    "\n",
    "# count()\n",
    "\n",
    "# Count occurrences of pattern\n",
    "\n",
    "# startswith()\n",
    "\n",
    "# Equivalent to str.startswith(pat) for each element\n",
    "\n",
    "# endswith()\n",
    "\n",
    "# Equivalent to str.endswith(pat) for each element\n",
    "\n",
    "# findall()\n",
    "\n",
    "# Compute list of all occurrences of pattern/regex for each string\n",
    "\n",
    "# match()\n",
    "\n",
    "# Call re.match on each element, returning matched groups as list\n",
    "\n",
    "# extract()\n",
    "\n",
    "# Call re.search on each element, returning DataFrame with one row for each element and one column for each regex capture group\n",
    "\n",
    "# extractall()\n",
    "\n",
    "# Call re.findall on each element, returning DataFrame with one row for each match and one column for each regex capture group\n",
    "\n",
    "# len()\n",
    "\n",
    "# Compute string lengths\n",
    "\n",
    "# strip()\n",
    "\n",
    "# Equivalent to str.strip\n",
    "\n",
    "# rstrip()\n",
    "\n",
    "# Equivalent to str.rstrip\n",
    "\n",
    "# lstrip()\n",
    "\n",
    "# Equivalent to str.lstrip\n",
    "\n",
    "# partition()\n",
    "\n",
    "# Equivalent to str.partition\n",
    "\n",
    "# rpartition()\n",
    "\n",
    "# Equivalent to str.rpartition\n",
    "\n",
    "# lower()\n",
    "\n",
    "# Equivalent to str.lower\n",
    "\n",
    "# casefold()\n",
    "\n",
    "# Equivalent to str.casefold\n",
    "\n",
    "# upper()\n",
    "\n",
    "# Equivalent to str.upper\n",
    "\n",
    "# find()\n",
    "\n",
    "# Equivalent to str.find\n",
    "\n",
    "# rfind()\n",
    "\n",
    "# Equivalent to str.rfind\n",
    "\n",
    "# index()\n",
    "\n",
    "# Equivalent to str.index\n",
    "\n",
    "# rindex()\n",
    "\n",
    "# Equivalent to str.rindex\n",
    "\n",
    "# capitalize()\n",
    "\n",
    "# Equivalent to str.capitalize\n",
    "\n",
    "# swapcase()\n",
    "\n",
    "# Equivalent to str.swapcase\n",
    "\n",
    "# normalize()\n",
    "\n",
    "# Return Unicode normal form. Equivalent to unicodedata.normalize\n",
    "\n",
    "# translate()\n",
    "\n",
    "# Equivalent to str.translate\n",
    "\n",
    "# isalnum()\n",
    "\n",
    "# Equivalent to str.isalnum\n",
    "\n",
    "# isalpha()\n",
    "\n",
    "# Equivalent to str.isalpha\n",
    "\n",
    "# isdigit()\n",
    "\n",
    "# Equivalent to str.isdigit\n",
    "\n",
    "# isspace()\n",
    "\n",
    "# Equivalent to str.isspace\n",
    "\n",
    "# islower()\n",
    "\n",
    "# Equivalent to str.islower\n",
    "\n",
    "# isupper()\n",
    "\n",
    "# Equivalent to str.isupper\n",
    "\n",
    "# istitle()\n",
    "\n",
    "# Equivalent to str.istitle\n",
    "\n",
    "# isnumeric()\n",
    "\n",
    "# Equivalent to str.isnumeric\n",
    "\n",
    "# isdecimal()\n",
    "\n",
    "# Equivalent to str.isdecimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(\n",
    "    [\"A\", \"B\", \"C\", \"Aaba\", \"Baca\", np.nan, \"CABA\", \"dog\", \"cat\"], dtype=\"string\"\n",
    ")\n",
    "\n",
    "\n",
    "s.str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Index also supports get_dummies which returns a MultiIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.Index([\"a\", \"a|b\", np.nan, \"a|c\"])\n",
    "idx.str.get_dummies(sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e57b5609a0adf6ef8af7ad6d2063e8e9c24ef6935f7306ae9ba467b68a2bc1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
